# Enterprise OTel Observability Stack

> [!IMPORTANT]
> **Current Status:** Phase 1 (Local) is **Complete**. Phase 2 (AWS) is **In Progress** (Step 13 ‚Äî Validation). All three ECS services (Grafana, Loki, App+ADOT) are live in AWS.

A production-grade, end-to-end observability platform for containerised applications using **OpenTelemetry** as the unified telemetry layer. Infrastructure, configuration, and dashboards are all managed as code.

## What This Is

This project demonstrates the three pillars of observability ‚Äî **Metrics, Logs, and Traces** ‚Äî wired together in a single, coherent pipeline:

- A **FastAPI** app instrumented with the OTel SDK emits all telemetry via OTLP
- **ADOT** (AWS Distro for OpenTelemetry) collects and routes everything
- **Prometheus / AMP** stores metrics, **Loki** stores logs, **X-Ray** stores traces
- **Grafana** visualises all three, with Log-to-Trace correlation

A **Locust** load generator and background metric/log emitters ensure the dashboards are always live ‚Äî no manual traffic needed.

## Dashboards

### Overview Dashboard
The Overview dashboard provides a high-level view of the system health, including metric-based request rates and simulated user counts alongside live Loki log streams.

![Grafana Dashboard](images/grafana-dashboard.png)

### Log-to-Trace Correlation
Expanding a log line in Loki reveals structured metadata, including the TraceID. This is linked natively to AWS X-Ray, allowing for seamless navigation to the waterfall view.

![X-Ray Trace Waterfall](images/traces-in-grafana.png)

## High-Level Architecture

```mermaid
flowchart TD
    LT["ü¶ó Locust<br/>Load Testing"]

    subgraph APP["Application Layer"]
        FA["üêç FastAPI App<br/>OpenTelemetry SDK"]
    end

    subgraph ADOT["Collection Layer ‚Äî ADOT Collector"]
        R["Receiver: OTLP"]
        P["Processors: batch ¬∑ resource"]
        E["Exporters: Prometheus remote_write ¬∑ Loki HTTP ¬∑ X-Ray"]
        R --> P --> E
    end

    subgraph BACKENDS["Backend Storage"]
        M["üìä Metrics<br/>Prometheus ¬∑ AMP"]
        L["üìÑ Logs<br/>Loki + MinIO ¬∑ Loki + S3"]
        T["üîç Traces<br/>X-Ray Daemon ¬∑ AWS X-Ray"]
    end

    subgraph VIZ["Visualization"]
        G["üìà Grafana OSS<br/>Dashboards as Code"]
    end

    LT -->|HTTP traffic| FA
    FA -->|OTLP gRPC| R
    E -->|remote_write| M
    E -->|HTTP| L
    E -->|UDP/TCP| T
    M --> G
    L --> G
    T --> G
```

## AWS Architecture

![AWS Architecture Diagram](images/aws-architecture.webp)

## Stack


| Feature / Signal | Local (All Containers) | AWS Production (ECS + Managed) | Type in AWS |
| :--- | :--- | :--- | :--- |
| **Application** | `app` | `app` | **ECS Container** |
| **Telemetry Collector** | `adot` (Standalone) | `adot` (Sidecar) | **ECS Container** |
| **Metrics Storage** | `prometheus` | **Amazon Managed Prometheus (AMP)** | **Managed Service** |
| **Log Database** | `loki` | `loki` | **ECS Container** |
| **Log Storage (Object)** | `minio` (S3 Simulator) | **Amazon S3** | **Managed Service** |
| **Trace Storage** | `xray-daemon` | **AWS X-Ray** | **Managed Service** |
| **Visualization** | `grafana` | `grafana` | **ECS Container** |
| **Load Generator** | `locust` | `locust` | **ECS Container** |
| **Traffic Direction** | Network Bridge | **Application Load Balancer (ALB)** | **Managed Service** |
| **Secrets / Config** | `.env` file | **SSM Parameter Store** | **Managed Service** |
| **IaC** | ‚Äî | **Terraform** | **Tooling** |
| **CI/CD** | ‚Äî | **GitHub Actions** | **Tooling** |


## Implementation Strategy

**Local first, then AWS.** The Docker Compose stack is a faithful simulation of the AWS architecture ‚Äî same ADOT config, same Grafana dashboards, same app code. Moving to AWS is a config swap, not a rewrite.

```
Phase 1 (Local)  ‚Üí  prove the pipeline works on Docker Desktop
Phase 2 (AWS)    ‚Üí  use Terraform to replicate the same pipes in the cloud
```

## Estimated AWS Cost

~$30/month for an always-on demo setup. Drops to ~$0 with `terraform destroy` between sessions (Terraform state persists in S3 for <$1/month).

## Repository Structure

```
.
‚îú‚îÄ‚îÄ app/                            # FastAPI app + OTel instrumentation
‚îú‚îÄ‚îÄ adot/                           # ADOT collector config (config.yaml)
‚îú‚îÄ‚îÄ grafana/
‚îÇ   ‚îú‚îÄ‚îÄ provisioning/               # Grafana datasource and dashboard provisioning
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ datasources/            # Grafana datasource provisioning
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ dashboards/             # Grafana dashboard provisioning
‚îÇ   ‚îî‚îÄ‚îÄ dashboard-definitions/      # Dashboard JSON files
‚îú‚îÄ‚îÄ locust/                         # Load test scripts
‚îú‚îÄ‚îÄ terraform/                      # All IaC ‚Äî ECS, AMP, S3, IAM (Phase 2)
‚îú‚îÄ‚îÄ .github/workflows/              # CI/CD pipeline (Phase 2)
‚îú‚îÄ‚îÄ docker-compose.yml              # Tech Stack (all 7 services)
‚îú‚îÄ‚îÄ prometheus.yml                  # Prometheus scrape config
‚îú‚îÄ‚îÄ loki-config.yaml                # Loki storage config (MinIO/S3 backend)
‚îú‚îÄ‚îÄ .env                            # Local env values (gitignored)
‚îú‚îÄ‚îÄ docs/                           
‚îÇ   ‚îú‚îÄ‚îÄ ARCHITECTURE.md             # Full architecture + ADRs + cost breakdown
‚îÇ   ‚îî‚îÄ‚îÄ IMPLEMENTATION_PLAN.md      # Step-by-step build checklist
‚îú‚îÄ‚îÄ AGENTS.md                       # Agent instructions and conventions
‚îî‚îÄ‚îÄ README.md                       # This file
```

## Docs

- [`docs/ARCHITECTURE.md`](./docs/ARCHITECTURE.md) ‚Äî Full architecture diagram, component decisions (ADRs), Phase 1 ‚Üí Phase 2 migration guide, and cost breakdown
- [`AGENTS.md`](./AGENTS.md) ‚Äî Agent instructions, architecture rules, and per-phase conventions
- [`docs/IMPLEMENTATION_PLAN.md`](./docs/IMPLEMENTATION_PLAN.md) ‚Äî Step-by-step build checklist for Phase 1 (local) and Phase 2 (AWS)
